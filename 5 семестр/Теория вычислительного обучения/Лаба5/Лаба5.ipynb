{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "712fd02c",
   "metadata": {},
   "source": [
    "<h1><center>Анализ тональности текста</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90459f4b",
   "metadata": {},
   "source": [
    "## Считывание датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39af1745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1af0241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_excel('doc_comment_summary.xlsx', sheet_name=0, header=None)\n",
    "dataset.columns = ('text', 'evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87fde5de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Но при мужчине ни одна приличная женщина не по...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Украина это часть Руси искусственно отделенная...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Как можно говорить об относительно небольшой к...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2014.  а что они со своими поляками сделали?...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>у а фильмы... Зрители любят диковинное.   у ме...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text evaluation\n",
       "0  Но при мужчине ни одна приличная женщина не по...         -1\n",
       "1  Украина это часть Руси искусственно отделенная...         -1\n",
       "2  Как можно говорить об относительно небольшой к...         -1\n",
       "3  1.2014.  а что они со своими поляками сделали?...          0\n",
       "4  у а фильмы... Зрители любят диковинное.   у ме...          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f630a4",
   "metadata": {},
   "source": [
    "## Предобработка датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1ba8aa",
   "metadata": {},
   "source": [
    "Удаляем все \"нейтральные\" комментарии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42422a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset['evaluation'] != 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0426e2b1",
   "metadata": {},
   "source": [
    "Почему-то не все комментарии являются строкой, как мы можем видеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f48e2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<class 'str'>, <class 'int'>, <class 'float'>], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'].apply(type).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3a18c8",
   "metadata": {},
   "source": [
    "Исправляем это."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f68bb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_col_wrong_types = dataset['text'].apply(lambda x: isinstance(x, int) or isinstance(x, float))\n",
    "dataset = dataset[~text_col_wrong_types].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c3b1652",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Но при мужчине ни одна приличная женщина не по...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Украина это часть Руси искусственно отделенная...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Как можно говорить об относительно небольшой к...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Государство не может сейчас платить больше и м...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>эксплуатируемые способны только на бунты - бес...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text evaluation\n",
       "0  Но при мужчине ни одна приличная женщина не по...         -1\n",
       "1  Украина это часть Руси искусственно отделенная...         -1\n",
       "2  Как можно говорить об относительно небольшой к...         -1\n",
       "3  Государство не может сейчас платить больше и м...         -1\n",
       "4  эксплуатируемые способны только на бунты - бес...         -1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4257dbb3",
   "metadata": {},
   "source": [
    "Так как я использовал алгоритмы бинарной классификации, а не регрессии, то нужно сократить количество классов до двух. В данном случае это просто: ставим \"негативный\" класс 0, если оценка меньше 0, иначе 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "811f3f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['evaluation'] = np.where(dataset['evaluation'] < 0, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c331794",
   "metadata": {},
   "source": [
    "## Проблема дисбаланса классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36514863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f62a44",
   "metadata": {},
   "source": [
    "Как мы можем видеть, негативных комментариев в разы больше положительных (классика). От этого необходимо избавиться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56c425bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10735\n",
       "1     2182\n",
       "Name: evaluation, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['evaluation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f82d42a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = RandomUnderSampler(random_state=42)\n",
    "dataset, _ = sampler.fit_resample(dataset, dataset['evaluation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ae1380",
   "metadata": {},
   "source": [
    "Просто удаляем случайным образом негативные комментарии, и проблема решена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1499f255",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2182\n",
       "1    2182\n",
       "Name: evaluation, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['evaluation'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f64afe",
   "metadata": {},
   "source": [
    "## Предобработка текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fc3dbb",
   "metadata": {},
   "source": [
    "Я решил оставить только русские буквы и считать это слово, обрамленное проблемами, словом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0844689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^а-яА-Я]', ' ', text)\n",
    "    text = re.sub(r'\\ {2,}', ' ', text)\n",
    "    text = text.strip().lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6e7210",
   "metadata": {},
   "source": [
    "Мы можем видеть пример работы моей функции обработки текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c557c27b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'что это зачем с какой целью для чего за каким читать сорокина не в том дело что не надо больше а в том что куда уже дальше возможно ли теперь больше ада по моему это предел человеческая фантазия не в силах вообразить себе нечто большее хотя и такое себе человек не вообразит меня на ночь клонит в метафизику было ли это великое зачеловеческое откровение или оно ещ только впереди в любом случае гордитесь россией мы на пороге великого метафизического прорыва в нечеловеческие сферы норвежские культисты ктулху фтагн чего только не придумает съехавшая с катушек баба ради денег и пиара дельсаль берсерк массакр'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text('..  1.Что ЭТО?!2.Зачем (с какой целью, для чего, за каким ...) читать Сорокина?  Не в том дело, что не надо больше, а в том что  Куда уже дальше? .  Возможно ли теперь  Больше ада ? По моему это предел, человеческая фантазия не в силах вообразить себе нечто большее (хотя и такое себе человек не вообразит). Меня на ночь клонит в метафизику - было ли это Великое зачеловеческое откровение или оно ещё только впереди? В любом случае гордитесь Россией мы на пороге великого метафизического прорыва в нечеловеческие сферы.   Норвежские культисты... Ктулху Фтагн !!!P.S. Чего только не придумает съехавшая с катушек баба... ради денег и пиара.  Дельсаль. Берсерк. Массакр')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465d7e88",
   "metadata": {},
   "source": [
    "Применим функцию к датасету."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b1b316d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    многие владельцы ипотек оказались раззоренными...\n",
       "1    другое дело что желающих иметь именно промышле...\n",
       "2    бстановка что надо послевкусие дайте две поско...\n",
       "3    то то никак крым себя не прокормит все дотации...\n",
       "4    ранее и штрафовали и народные дружинники по ул...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'] = dataset['text'].apply(preprocess_text)\n",
    "dataset['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715a4ed2",
   "metadata": {},
   "source": [
    "## Разделение выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9dde347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d294db8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_train, docs_test, evals_train, evals_test = train_test_split(dataset['text'], dataset['evaluation'], train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047adfba",
   "metadata": {},
   "source": [
    "## Векторизация слов в тексте"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acf91ca",
   "metadata": {},
   "source": [
    "В качестве метода сегментезции текста был использован метод **TF-IDF**, а в качестве алгоритма обработки слов был использован **стемминг**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a8da391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize, download   \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8bfef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(language='russian')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bb2ea0",
   "metadata": {},
   "source": [
    "Пример работы стемминга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "13a78b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'аграрн'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('аграрный')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9d0682",
   "metadata": {},
   "source": [
    "Функция токенизации (разбиения текста на слова)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28647ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = text.split()\n",
    "    stems = [stemmer.stem(item) for item in tokens if item not in stopwords.words('russian')]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33c699b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4bb6fcb7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vectors_arr = vectorizer.fit_transform(docs_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9b69ed",
   "metadata": {},
   "source": [
    "Как мы можем видеть, у нас 32777 слов (колонок в таблице), что очень много и грустно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2d92c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3491, 32777)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234a363e",
   "metadata": {},
   "source": [
    "Пример стеммизированных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80bd4dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['аборт',\n",
       " 'абортивн',\n",
       " 'абортмахер',\n",
       " 'абр',\n",
       " 'абрам',\n",
       " 'абрамов',\n",
       " 'абрамович',\n",
       " 'абрамовн',\n",
       " 'абрамс',\n",
       " 'абрамыч']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[30:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "348a8d26",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>а</th>\n",
       "      <th>аа</th>\n",
       "      <th>ааа</th>\n",
       "      <th>аааа</th>\n",
       "      <th>ааааа</th>\n",
       "      <th>аааааа</th>\n",
       "      <th>аааааааа</th>\n",
       "      <th>аааааааааа</th>\n",
       "      <th>ааааааааааа</th>\n",
       "      <th>...</th>\n",
       "      <th>ячейк</th>\n",
       "      <th>яш</th>\n",
       "      <th>яшин</th>\n",
       "      <th>яшк</th>\n",
       "      <th>ящета</th>\n",
       "      <th>ящик</th>\n",
       "      <th>ящита</th>\n",
       "      <th>ящичек</th>\n",
       "      <th>ящэ</th>\n",
       "      <th>яяяя</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3488</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3489</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3490</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3491 rows × 32777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             а   аа  ааа  аааа  ааааа  аааааа  аааааааа  аааааааааа  \\\n",
       "0     0.0  0.0  0.0  0.0   0.0    0.0     0.0       0.0         0.0   \n",
       "1     0.0  0.0  0.0  0.0   0.0    0.0     0.0       0.0         0.0   \n",
       "2     0.0  0.0  0.0  0.0   0.0    0.0     0.0       0.0         0.0   \n",
       "3     0.0  0.0  0.0  0.0   0.0    0.0     0.0       0.0         0.0   \n",
       "4     0.0  0.0  0.0  0.0   0.0    0.0     0.0       0.0         0.0   \n",
       "...   ...  ...  ...  ...   ...    ...     ...       ...         ...   \n",
       "3486  0.0  0.0  0.0  0.0   0.0    0.0     0.0       0.0         0.0   \n",
       "3487  0.0  0.0  0.0  0.0   0.0    0.0     0.0       0.0         0.0   \n",
       "3488  0.0  0.0  0.0  0.0   0.0    0.0     0.0       0.0         0.0   \n",
       "3489  0.0  0.0  0.0  0.0   0.0    0.0     0.0       0.0         0.0   \n",
       "3490  0.0  0.0  0.0  0.0   0.0    0.0     0.0       0.0         0.0   \n",
       "\n",
       "      ааааааааааа  ...  ячейк   яш  яшин  яшк  ящета  ящик  ящита  ящичек  \\\n",
       "0             0.0  ...    0.0  0.0   0.0  0.0    0.0   0.0    0.0     0.0   \n",
       "1             0.0  ...    0.0  0.0   0.0  0.0    0.0   0.0    0.0     0.0   \n",
       "2             0.0  ...    0.0  0.0   0.0  0.0    0.0   0.0    0.0     0.0   \n",
       "3             0.0  ...    0.0  0.0   0.0  0.0    0.0   0.0    0.0     0.0   \n",
       "4             0.0  ...    0.0  0.0   0.0  0.0    0.0   0.0    0.0     0.0   \n",
       "...           ...  ...    ...  ...   ...  ...    ...   ...    ...     ...   \n",
       "3486          0.0  ...    0.0  0.0   0.0  0.0    0.0   0.0    0.0     0.0   \n",
       "3487          0.0  ...    0.0  0.0   0.0  0.0    0.0   0.0    0.0     0.0   \n",
       "3488          0.0  ...    0.0  0.0   0.0  0.0    0.0   0.0    0.0     0.0   \n",
       "3489          0.0  ...    0.0  0.0   0.0  0.0    0.0   0.0    0.0     0.0   \n",
       "3490          0.0  ...    0.0  0.0   0.0  0.0    0.0   0.0    0.0     0.0   \n",
       "\n",
       "      ящэ  яяяя  \n",
       "0     0.0   0.0  \n",
       "1     0.0   0.0  \n",
       "2     0.0   0.0  \n",
       "3     0.0   0.0  \n",
       "4     0.0   0.0  \n",
       "...   ...   ...  \n",
       "3486  0.0   0.0  \n",
       "3487  0.0   0.0  \n",
       "3488  0.0   0.0  \n",
       "3489  0.0   0.0  \n",
       "3490  0.0   0.0  \n",
       "\n",
       "[3491 rows x 32777 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = pd.DataFrame(data=vectors_arr.todense(), columns=vectorizer.get_feature_names())\n",
    "vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f55171",
   "metadata": {},
   "source": [
    "32777 колонок. Ужас."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b40ec3",
   "metadata": {},
   "source": [
    "## Построение моделей классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "085d440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "663028f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_model(model, y_true):\n",
    "    model_evals = model.predict(vectorizer.transform(docs_test).todense())\n",
    "    return confusion_matrix(evals_test, model_evals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd6134c",
   "metadata": {},
   "source": [
    "### Наивный байесовский классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56822b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnd = GaussianNB()\n",
    "gnb.fit(vectors, evals_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a41b533",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[309, 160],\n",
       "       [127, 277]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assess_model(gnb, evals_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f661ac79",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c4b2aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(cache_size=600, class_weight='balanced')\n",
    "svc.fit(vectors, evals_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50febcb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[386,  83],\n",
       "       [127, 277]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assess_model(svc, evals_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c37b092",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db0c3343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(vectors, evals_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc8035c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[320, 149],\n",
       "       [139, 265]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assess_model(dtc, evals_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736a7121",
   "metadata": {},
   "source": [
    "## Подход на основе тонального словаря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a9b3207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pymorphy2 import MorphAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b790c9",
   "metadata": {},
   "source": [
    "Считывание данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fa50fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_eval = pd.read_excel('full word_rating_after_coding.xlsx', sheet_name=0, header=None)\n",
    "words_eval.columns = ('word', 'evaluation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e28ce53",
   "metadata": {},
   "source": [
    "Так как каждое слово представлено в таблице, как правило, несколькими оценками, которые могут разниться, я принял решение суммировать все оценки для каждого слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c515d8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>абажур</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>абориген</th>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>аборт</th>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>абортивный</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>абсолютный</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ясность</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ясный</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>яхта</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>яшин</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ящик</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6860 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            evaluation\n",
       "word                  \n",
       "абажур              -1\n",
       "абориген            -2\n",
       "аборт               -3\n",
       "абортивный          -1\n",
       "абсолютный           0\n",
       "...                ...\n",
       "ясность              1\n",
       "ясный                1\n",
       "яхта                 0\n",
       "яшин                 0\n",
       "ящик                 0\n",
       "\n",
       "[6860 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_eval = words_eval.groupby('word').sum('evaluation')\n",
    "words_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a9c68b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>волшебный</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           evaluation\n",
       "word                 \n",
       "волшебный          10"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_eval.iloc[[np.argmax(words_eval.values)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "acaca745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>волшебный</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>доброта</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           evaluation\n",
       "word                 \n",
       "волшебный          10\n",
       "доброта            10"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_eval[words_eval['evaluation'] == 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd06e9a",
   "metadata": {},
   "source": [
    "Сделаем из текста список слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e31d35a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1760    [головный, кодекс, когда, неверие, неверующих,...\n",
       "51      [нова, пошла, на, сговор, и, дала, добро, на, ...\n",
       "4308    [блюющие, на, пасху, христиане, полагаю, все, ...\n",
       "2292    [путин, всего, достиг, сам, и, без, чье, либо,...\n",
       "1044    [васяню, можно, ругать, как, хошь, а, вот, дру...\n",
       "                              ...                        \n",
       "3113    [де, просто, статистика, беда, скоро, кто, про...\n",
       "1398    [многих, остались, принципиальные, вопросы, не...\n",
       "3184    [у, меня, вопрос, совсем, глупый, почему, л, с...\n",
       "809     [бедные, они, то, ли, дело, в, целом, поддержи...\n",
       "1659    [все, беды, от, бап, да, какой, в, жопу, верто...\n",
       "Name: text, Length: 873, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_words = docs_test.apply(lambda text: text.split())\n",
    "docs_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fc817d",
   "metadata": {},
   "source": [
    "Преобразуем таблицу в словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b254c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_dict = dict([(k, v) for k, v in zip(words_eval.index, words_eval['evaluation'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a3f10d",
   "metadata": {},
   "source": [
    "Применяем **лемматизацию** для изменения слов. Сильно влияет на результат (в положительную сторону, конечно)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fa70a25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1760    [головный, кодекс, неверие, неверующий, станов...\n",
       "51      [новый, пойти, сговор, дать, добро, агрессия, ...\n",
       "4308    [блевать, пасха, христианин, полагать, метафор...\n",
       "2292    [путин, достигнуть, чей, либо, помощь, такой, ...\n",
       "1044    [васянить, ругать, хотеть, другой, низзить, ди...\n",
       "                              ...                        \n",
       "3113    [де, просто, статистика, беда, скоро, проезжат...\n",
       "1398    [многий, остаться, принципиальный, вопрос, физ...\n",
       "3184    [вопрос, глупый, почему, л, расположение, одет...\n",
       "809     [бедный, дело, целое, поддерживать, ответить, ...\n",
       "1659    [беда, бап, жопа, вертолетоносец, война, франц...\n",
       "Name: text, Length: 873, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph = MorphAnalyzer()\n",
    "docs_words = docs_words.apply(lambda words: [morph.parse(word)[0].normal_form for word in words if word not in stopwords.words('russian')])\n",
    "docs_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e91eec6",
   "metadata": {},
   "source": [
    "Получаем список оценок для каждого комментария"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb2171d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1760   -10\n",
       "51     -29\n",
       "4308    -6\n",
       "2292    17\n",
       "1044   -51\n",
       "        ..\n",
       "3113   -20\n",
       "1398     7\n",
       "3184    15\n",
       "809    -38\n",
       "1659   -26\n",
       "Name: text, Length: 873, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tone_dict_score = docs_words.apply(lambda text: sum(map(lambda word: tone_dict.get(word, 0), text)))\n",
    "tone_dict_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14506044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "-167\n"
     ]
    }
   ],
   "source": [
    "print(tone_dict_score.max())\n",
    "print(tone_dict_score.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783fc5c6",
   "metadata": {},
   "source": [
    "Бинаризуем их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "799bde66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions  = [tone_dict_score < 0, tone_dict_score > 0, tone_dict_score == 0]\n",
    "choices     = [0, 1, random.randint(0, 1)]\n",
    "tone_dict_eval = np.select(conditions, choices)\n",
    "tone_dict_eval[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf8c6f",
   "metadata": {},
   "source": [
    "Результат хуже SVM. Очень странно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c96ca6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[389,  80],\n",
       "       [171, 233]], dtype=int64)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(evals_test, tone_dict_eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
